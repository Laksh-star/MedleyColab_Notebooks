{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install pytube opencv-python pillow pytesseract numpy\n",
        "\n",
        "# Install tesseract OCR\n",
        "!apt-get install tesseract-ocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8D7Dpu6n78H",
        "outputId": "992b1356-4e8d-4af0-c4a5-1f3cdfe41cda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytube in /usr/local/lib/python3.10/dist-packages (15.0.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 1s (6,065 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 123630 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yt-dlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZngBu4Eeq3HQ",
        "outputId": "10bcdf95-3944-4ab5-a882-72024b8c88c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2024.11.18-py3-none-any.whl.metadata (172 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/172.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.1/172.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2024.11.18-py3-none-any.whl (3.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m2.9/3.2 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt-dlp\n",
            "Successfully installed yt-dlp-2024.11.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDdK-Y9sp-8z",
        "outputId": "cf244fc4-789e-42d4-9428-17c99fe8a53c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytube in /usr/local/lib/python3.10/dist-packages (15.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install anthropic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RD6ssyIt4aM",
        "outputId": "815f9ef7-33de-4556-937a-cf59658d8d7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anthropic\n",
            "  Downloading anthropic-0.39.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from anthropic) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.23.4)\n",
            "Downloading anthropic-0.39.0-py3-none-any.whl (198 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/198.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.4/198.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic\n",
            "Successfully installed anthropic-0.39.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p_aWrGU1ooLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3kYMzySntGI"
      },
      "outputs": [],
      "source": [
        "# Without LLM\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import List, Optional, Dict, Any\n",
        "import json\n",
        "from datetime import datetime\n",
        "import asyncio\n",
        "import yt_dlp\n",
        "\n",
        "class EnhancedJSONEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.integer):\n",
        "            return int(obj)\n",
        "        if isinstance(obj, np.floating):\n",
        "            return float(obj)\n",
        "        if isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        if isinstance(obj, (tuple, set)):\n",
        "            return list(obj)\n",
        "        return super().default(obj)\n",
        "\n",
        "@dataclass\n",
        "class AdDetails:\n",
        "    video_id: str\n",
        "    video_title: str\n",
        "    timestamp: float\n",
        "    ad_text: str\n",
        "    confidence_score: float\n",
        "    ad_position: tuple\n",
        "    processed_date: str\n",
        "\n",
        "    def to_dict(self) -> Dict[str, Any]:\n",
        "        \"\"\"Convert AdDetails to a dictionary with properly converted types.\"\"\"\n",
        "        result = asdict(self)\n",
        "        # Convert tuple to list for JSON serialization\n",
        "        result['ad_position'] = list(result['ad_position'])\n",
        "        return result\n",
        "\n",
        "class YouTubeAdScanner:\n",
        "    def __init__(self, playlist_url: str, output_dir: str = \"ad_scan_results\"):\n",
        "        self.playlist_url = playlist_url\n",
        "        self.output_dir = output_dir\n",
        "        self.results: List[AdDetails] = []\n",
        "\n",
        "        # Create output directories\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        os.makedirs(os.path.join(output_dir, \"frames\"), exist_ok=True)\n",
        "        os.makedirs(os.path.join(output_dir, \"temp\"), exist_ok=True)\n",
        "\n",
        "        # Configure yt-dlp options\n",
        "        self.ydl_opts = {\n",
        "            'format': 'best[height<=720]',\n",
        "            'quiet': True,\n",
        "            'no_warnings': True,\n",
        "            'extract_flat': True,\n",
        "        }\n",
        "\n",
        "    def get_playlist_videos(self):\n",
        "        with yt_dlp.YoutubeDL(self.ydl_opts) as ydl:\n",
        "            try:\n",
        "                playlist_info = ydl.extract_info(self.playlist_url, download=False)\n",
        "                if 'entries' in playlist_info:\n",
        "                    return [(entry['id'], entry['title']) for entry in playlist_info['entries']]\n",
        "                return []\n",
        "            except Exception as e:\n",
        "                print(f\"Error extracting playlist info: {str(e)}\")\n",
        "                return []\n",
        "\n",
        "    def extract_frames(self, video_path: str, num_frames: int = 5) -> List[np.ndarray]:\n",
        "        frames = []\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "        for _ in range(num_frames):\n",
        "            ret, frame = cap.read()\n",
        "            if ret:\n",
        "                frames.append(frame)\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        cap.release()\n",
        "        return frames\n",
        "\n",
        "    def detect_ad_strip(self, frame: np.ndarray) -> Optional[tuple]:\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        edges = cv2.Canny(gray, 50, 150)\n",
        "\n",
        "        height = frame.shape[0]\n",
        "        bottom_third = edges[2*height//3:]\n",
        "\n",
        "        lines = cv2.HoughLinesP(bottom_third, 1, np.pi/180, 100,\n",
        "                               minLineLength=frame.shape[1]//3, maxLineGap=20)\n",
        "\n",
        "        if lines is not None:\n",
        "            max_length = 0\n",
        "            best_line = None\n",
        "\n",
        "            for line in lines:\n",
        "                x1, y1, x2, y2 = line[0]\n",
        "                if abs(y2 - y1) < 10:\n",
        "                    length = abs(x2 - x1)\n",
        "                    if length > max_length:\n",
        "                        max_length = length\n",
        "                        best_line = line[0]\n",
        "\n",
        "            if best_line is not None:\n",
        "                x1, y1, x2, y2 = best_line\n",
        "                return (0, y1 + 2*height//3 - 50, frame.shape[1], 50)\n",
        "\n",
        "        return None\n",
        "\n",
        "    def preprocess_image_for_ocr(self, image: np.ndarray) -> List[np.ndarray]:\n",
        "        \"\"\"Apply different preprocessing techniques to improve OCR accuracy.\"\"\"\n",
        "        preprocessed_images = []\n",
        "\n",
        "        # Original image\n",
        "        preprocessed_images.append(image)\n",
        "\n",
        "        # Convert to grayscale and apply threshold\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        _, thresh1 = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "        preprocessed_images.append(cv2.cvtColor(thresh1, cv2.COLOR_GRAY2BGR))\n",
        "\n",
        "        # Apply adaptive threshold\n",
        "        adaptive_thresh = cv2.adaptiveThreshold(\n",
        "            gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "        preprocessed_images.append(cv2.cvtColor(adaptive_thresh, cv2.COLOR_GRAY2BGR))\n",
        "\n",
        "        # Increase contrast\n",
        "        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "        l, a, b = cv2.split(lab)\n",
        "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
        "        cl = clahe.apply(l)\n",
        "        enhanced = cv2.merge((cl, a, b))\n",
        "        enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)\n",
        "        preprocessed_images.append(enhanced)\n",
        "\n",
        "        return preprocessed_images\n",
        "\n",
        "    def extract_ad_text(self, frame: np.ndarray, ad_region: tuple) -> tuple:\n",
        "        \"\"\"Extract text from the ad region using multiple preprocessing techniques.\"\"\"\n",
        "        x, y, w, h = ad_region\n",
        "        ad_image = frame[y:y+h, x:x+w]\n",
        "\n",
        "        # Scale up the image to improve OCR\n",
        "        scaled_image = cv2.resize(ad_image, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "        # Get preprocessed versions of the image\n",
        "        preprocessed_images = self.preprocess_image_for_ocr(scaled_image)\n",
        "\n",
        "        best_text = \"\"\n",
        "        best_confidence = 0\n",
        "\n",
        "        # Custom configuration for Tesseract\n",
        "        custom_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789 ,.!?-\"'\n",
        "\n",
        "        for img in preprocessed_images:\n",
        "            # Convert to PIL Image\n",
        "            pil_image = Image.fromarray(img)\n",
        "\n",
        "            # Try OCR with different page segmentation modes\n",
        "            for psm in [6, 7, 3]:  # Single uniform block, single text line, auto\n",
        "                try:\n",
        "                    config = f'--oem 3 --psm {psm} {custom_config}'\n",
        "                    ocr_data = pytesseract.image_to_data(pil_image, config=config,\n",
        "                                                       output_type=pytesseract.Output.DICT)\n",
        "\n",
        "                    text_parts = []\n",
        "                    confidence_sum = 0\n",
        "                    confidence_count = 0\n",
        "\n",
        "                    for i in range(len(ocr_data['text'])):\n",
        "                        conf = int(ocr_data['conf'][i])\n",
        "                        if conf > 0:\n",
        "                            text_parts.append(ocr_data['text'][i])\n",
        "                            confidence_sum += float(conf)\n",
        "                            confidence_count += 1\n",
        "\n",
        "                    if confidence_count > 0:\n",
        "                        text = \" \".join(text_parts).strip()\n",
        "                        avg_confidence = confidence_sum / confidence_count\n",
        "\n",
        "                        # Keep the result with highest confidence\n",
        "                        if avg_confidence > best_confidence and len(text) > 3:\n",
        "                            best_text = text\n",
        "                            best_confidence = avg_confidence\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"OCR error with PSM {psm}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "        # Additional post-processing of the text\n",
        "        if best_text:\n",
        "            # Remove extra whitespace\n",
        "            best_text = \" \".join(best_text.split())\n",
        "\n",
        "            # Remove common OCR artifacts\n",
        "            best_text = re.sub(r'[^\\w\\s.,!?-]', '', best_text)\n",
        "\n",
        "            # Save the processed image for debugging\n",
        "            debug_path = os.path.join(self.output_dir, \"frames\", f\"debug_ocr_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg\")\n",
        "            cv2.imwrite(debug_path, scaled_image)\n",
        "\n",
        "        return best_text, best_confidence\n",
        "\n",
        "    async def process_video(self, video_id: str, video_title: str):\n",
        "        try:\n",
        "            print(f\"Processing video: {video_title} ({video_id})\")\n",
        "\n",
        "            video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "            ydl_opts = {\n",
        "                'format': 'best[height<=720]',\n",
        "                'quiet': True,\n",
        "                'no_warnings': True,\n",
        "                'outtmpl': os.path.join(self.output_dir, \"temp\", f\"{video_id}.%(ext)s\")\n",
        "            }\n",
        "\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                info = ydl.extract_info(video_url, download=True)\n",
        "                video_path = ydl.prepare_filename(info)\n",
        "\n",
        "            if os.path.exists(video_path):\n",
        "                frames = self.extract_frames(video_path)\n",
        "\n",
        "                for frame_idx, frame in enumerate(frames):\n",
        "                    ad_region = self.detect_ad_strip(frame)\n",
        "\n",
        "                    if ad_region:\n",
        "                        frame_path = os.path.join(\n",
        "                            self.output_dir, \"frames\",\n",
        "                            f\"{video_id}_frame_{frame_idx}.jpg\")\n",
        "                        cv2.imwrite(frame_path, frame)\n",
        "\n",
        "                        ad_text, confidence = self.extract_ad_text(frame, ad_region)\n",
        "\n",
        "                        if ad_text:\n",
        "                            ad_details = AdDetails(\n",
        "                                video_id=video_id,\n",
        "                                video_title=video_title,\n",
        "                                timestamp=float(frame_idx) / 30.0,  # Convert to float explicitly\n",
        "                                ad_text=ad_text,\n",
        "                                confidence_score=float(confidence),  # Convert to float explicitly\n",
        "                                ad_position=tuple(int(x) for x in ad_region),  # Convert to regular integers\n",
        "                                processed_date=datetime.now().isoformat()\n",
        "                            )\n",
        "                            self.results.append(ad_details)\n",
        "                            print(f\"Found ad in video {video_id} at frame {frame_idx}\")\n",
        "                            print(f\"Ad text: {ad_text}\")\n",
        "\n",
        "                os.remove(video_path)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing video {video_id}: {str(e)}\")\n",
        "\n",
        "    async def process_playlist(self):\n",
        "        try:\n",
        "            print(f\"Processing playlist: {self.playlist_url}\")\n",
        "            videos = self.get_playlist_videos()\n",
        "\n",
        "            if not videos:\n",
        "                print(\"No videos found in playlist\")\n",
        "                return\n",
        "\n",
        "            print(f\"Found {len(videos)} videos\")\n",
        "\n",
        "            semaphore = asyncio.Semaphore(2)\n",
        "\n",
        "            async def process_with_semaphore(video_id, video_title):\n",
        "                async with semaphore:\n",
        "                    await self.process_video(video_id, video_title)\n",
        "                    await asyncio.sleep(1)\n",
        "\n",
        "            tasks = [process_with_semaphore(vid_id, title) for vid_id, title in videos]\n",
        "            await asyncio.gather(*tasks)\n",
        "\n",
        "            self.save_results()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing playlist: {str(e)}\")\n",
        "            raise  # Re-raise the exception to see the full traceback\n",
        "\n",
        "    def save_results(self):\n",
        "        \"\"\"Save scanning results to a JSON file.\"\"\"\n",
        "        results_file = os.path.join(self.output_dir, \"scan_results.json\")\n",
        "\n",
        "        # Convert results to dictionaries with proper type conversion\n",
        "        results_data = [result.to_dict() for result in self.results]\n",
        "\n",
        "        with open(results_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(results_data, f, indent=2, cls=EnhancedJSONEncoder, ensure_ascii=False)\n",
        "\n",
        "        print(f\"Results saved to {results_file}\")\n",
        "        print(f\"Found {len(self.results)} ads across all videos\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "playlist_url = \"https://www.youtube.com/playlist?list=PLTycFjvfXg-sYpyfA4a_lcIbMXhVtQrxO\"\n",
        "scanner = YouTubeAdScanner(playlist_url)\n",
        "await scanner.process_playlist()  # Use await directly in Colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CvhEqy_pLjz",
        "outputId": "e2fcea66-d857-455a-f505-81914708a6b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing playlist: https://www.youtube.com/playlist?list=PLTycFjvfXg-sYpyfA4a_lcIbMXhVtQrxO\n",
            "Found 4 videos\n",
            "Processing video: PM Modi Hails Mahayuti Landslide Victory In Maharashtra Elections | Ntv (oP-xZpQkOJ4)\n",
            "Processing video: కార్తిక శనివారం శుభవేళ లింగ రూపంలో సాక్షాత్కారం అయినా శివుడిని దర్శించడం మహాద్భుతం | Lingodbhavam (4FR4MHGMj0o)\n",
            "Found ad in video 4FR4MHGMj0o at frame 0\n",
            "Ad text: hE Ty, ry ce ght. BR\n",
            "Found ad in video 4FR4MHGMj0o at frame 1\n",
            "Ad text: a mal 7 4 J PY ti I vg ni 7, 7\n",
            "Found ad in video 4FR4MHGMj0o at frame 2\n",
            "Ad text: ine id J eae ee\n",
            "Found ad in video 4FR4MHGMj0o at frame 3\n",
            "Ad text: 7 wh Pe A a\n",
            "Found ad in video 4FR4MHGMj0o at frame 4\n",
            "Ad text: et J t- ey crs\n",
            "Processing video: కోటి దీపోత్సవ జ్ఞానదీపాన్ని వెలిగించిన తర్వాత మీ ఇష్టదైవాన్ని స్మరించండి.. సకల శుభాలు చేకూరుతాయి..! (sHVqXoWQrZ4)\n",
            "Found ad in video sHVqXoWQrZ4 at frame 0\n",
            "Ad text: a ee a ee I al a ee ER ee Or Se a ee. ary We Ak Oe\n",
            "Found ad in video sHVqXoWQrZ4 at frame 1\n",
            "Ad text: ae A ee 4 i ri i, sy . Sd a a, eee 7 Bn, oe. SS Og 4 nS ey a\n",
            "Found ad in video sHVqXoWQrZ4 at frame 2\n",
            "Ad text: a Le gs. i\n",
            "Found ad in video sHVqXoWQrZ4 at frame 3\n",
            "Ad text: cote id a - Pee 2 3 gs. ee. we. a\n",
            "Found ad in video sHVqXoWQrZ4 at frame 4\n",
            "Ad text: a hs a op ais 4 my - om Ws bog Ae\n",
            "Processing video: తెలంగాణ మంత్రి శ్రీ కోమటిరెడ్డి వెంకట్ రెడ్డి గారి ఆధ్యాత్మిక ప్రసంగం : Sri Komatireddy Venkat Reddy (GYFHrXMgnD8)\n",
            "Found ad in video GYFHrXMgnD8 at frame 0\n",
            "Ad text: 4 a ae, a Aa ee pi? x i. ia ae one ede a oa ry Se ed. tom 5 ey Sey ax Sais FP ee Pca ee oo a.\n",
            "Found ad in video GYFHrXMgnD8 at frame 1\n",
            "Ad text: Fee par oe a a pe ne. ae peer , aw heed ae, a x, 2 ERLE egal nn Oi .\n",
            "Found ad in video GYFHrXMgnD8 at frame 2\n",
            "Ad text: La ae ad See.\n",
            "Found ad in video GYFHrXMgnD8 at frame 3\n",
            "Ad text: te ES - ag 3 OP ES GR. eS Se ee Se ee Oe ee oe oat go ee\n",
            "Found ad in video GYFHrXMgnD8 at frame 4\n",
            "Ad text: ee on FF Pa wa as,\n",
            "Results saved to ad_scan_results/scan_results.json\n",
            "Found 15 ads across all videos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# With Vision LLM- Claude Version 1.0 and 2.0\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import List, Optional, Dict, Any\n",
        "import json\n",
        "from datetime import datetime\n",
        "import asyncio\n",
        "import yt_dlp\n",
        "import anthropic\n",
        "import base64\n",
        "import io\n",
        "\n",
        "# Replace this with your API key\n",
        "CLAUDE_API_KEY = \"Your_api_key_here\"\n",
        "\n",
        "@dataclass\n",
        "class AdDetails:\n",
        "    video_id: str\n",
        "    video_title: str\n",
        "    timestamp: float\n",
        "    ad_text: str\n",
        "    confidence_score: float\n",
        "    ad_position: tuple\n",
        "    processed_date: str\n",
        "\n",
        "    def to_dict(self) -> Dict[str, Any]:\n",
        "        result = asdict(self)\n",
        "        result['ad_position'] = list(result['ad_position'])\n",
        "        return result\n",
        "\n",
        "class YouTubeAdScanner:\n",
        "    def __init__(self, playlist_url: str, output_dir: str = \"ad_scan_results\"):\n",
        "        self.playlist_url = playlist_url\n",
        "        self.output_dir = output_dir\n",
        "        self.results: List[AdDetails] = []\n",
        "        self.client = anthropic.Anthropic(api_key=CLAUDE_API_KEY)\n",
        "\n",
        "        # Create output directories\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        os.makedirs(os.path.join(output_dir, \"frames\"), exist_ok=True)\n",
        "        os.makedirs(os.path.join(output_dir, \"temp\"), exist_ok=True)\n",
        "\n",
        "        # Configure yt-dlp options\n",
        "        self.ydl_opts = {\n",
        "            'format': 'best[height<=720]',\n",
        "            'quiet': True,\n",
        "            'no_warnings': True,\n",
        "            'extract_flat': True,\n",
        "        }\n",
        "\n",
        "    def get_playlist_videos(self):\n",
        "        with yt_dlp.YoutubeDL(self.ydl_opts) as ydl:\n",
        "            try:\n",
        "                playlist_info = ydl.extract_info(self.playlist_url, download=False)\n",
        "                if 'entries' in playlist_info:\n",
        "                    return [(entry['id'], entry['title']) for entry in playlist_info['entries']]\n",
        "                return []\n",
        "            except Exception as e:\n",
        "                print(f\"Error extracting playlist info: {str(e)}\")\n",
        "                return []\n",
        "\n",
        "    def extract_frames(self, video_path: str, num_frames: int = 5) -> List[np.ndarray]:\n",
        "        frames = []\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "        for _ in range(num_frames):\n",
        "            ret, frame = cap.read()\n",
        "            if ret:\n",
        "                frames.append(frame)\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        cap.release()\n",
        "        return frames\n",
        "\n",
        "    def detect_ad_strip(self, frame: np.ndarray) -> Optional[tuple]:\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        edges = cv2.Canny(gray, 50, 150)\n",
        "\n",
        "        height = frame.shape[0]\n",
        "        bottom_third = edges[2*height//3:]\n",
        "\n",
        "        lines = cv2.HoughLinesP(bottom_third, 1, np.pi/180, 100,\n",
        "                               minLineLength=frame.shape[1]//3, maxLineGap=20)\n",
        "\n",
        "        if lines is not None:\n",
        "            max_length = 0\n",
        "            best_line = None\n",
        "\n",
        "            for line in lines:\n",
        "                x1, y1, x2, y2 = line[0]\n",
        "                if abs(y2 - y1) < 10:\n",
        "                    length = abs(x2 - x1)\n",
        "                    if length > max_length:\n",
        "                        max_length = length\n",
        "                        best_line = line[0]\n",
        "\n",
        "            if best_line is not None:\n",
        "                x1, y1, x2, y2 = best_line\n",
        "                return (0, y1 + 2*height//3 - 50, frame.shape[1], 50)\n",
        "\n",
        "        return None\n",
        "\n",
        "    def image_to_base64(self, image: np.ndarray) -> str:\n",
        "        \"\"\"Convert an OpenCV image to base64 string.\"\"\"\n",
        "        # Convert from BGR to RGB\n",
        "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Convert to PIL Image\n",
        "        pil_image = Image.fromarray(image_rgb)\n",
        "\n",
        "        # Save to bytes buffer\n",
        "        buffer = io.BytesIO()\n",
        "        pil_image.save(buffer, format='JPEG')\n",
        "\n",
        "        # Get base64 string\n",
        "        base64_string = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
        "        return base64_string\n",
        "\n",
        "    async def extract_text_with_claude(self, frame: np.ndarray, ad_region: tuple) -> tuple:\n",
        "        \"\"\"Extract text from image using Claude's vision capabilities.\"\"\"\n",
        "        try:\n",
        "            x, y, w, h = ad_region\n",
        "            ad_image = frame[y:y+h, x:x+w]\n",
        "\n",
        "            # Convert image to base64\n",
        "            image_base64 = self.image_to_base64(ad_image)\n",
        "\n",
        "            # Create message with Claude\n",
        "            message = self.client.messages.create(\n",
        "                model=\"claude-3-5-sonnet-20241022\",\n",
        "                max_tokens=1024,\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": [\n",
        "                            {\n",
        "                                \"type\": \"image\",\n",
        "                                \"source\": {\n",
        "                                    \"type\": \"base64\",\n",
        "                                    \"media_type\": \"image/jpeg\",\n",
        "                                    \"data\": image_base64,\n",
        "                                },\n",
        "                            },\n",
        "                            {\n",
        "                                \"type\": \"text\",\n",
        "                                \"text\": \"What logos and text appears in this image?\"\n",
        "                            }\n",
        "                        ],\n",
        "                    }\n",
        "                ],\n",
        "            )\n",
        "\n",
        "            # Extract text from Claude's response\n",
        "            extracted_text = message.content[0].text.strip()\n",
        "\n",
        "            # For now, use a fixed confidence score since Claude doesn't provide one\n",
        "            confidence_score = 0.9 if extracted_text else 0.0\n",
        "\n",
        "            return extracted_text, confidence_score\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error using Claude for text extraction: {str(e)}\")\n",
        "            return \"\", 0.0\n",
        "\n",
        "    async def process_video(self, video_id: str, video_title: str):\n",
        "        try:\n",
        "            print(f\"Processing video: {video_title} ({video_id})\")\n",
        "\n",
        "            video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "            ydl_opts = {\n",
        "                'format': 'best[height<=720]',\n",
        "                'quiet': True,\n",
        "                'no_warnings': True,\n",
        "                'outtmpl': os.path.join(self.output_dir, \"temp\", f\"{video_id}.%(ext)s\")\n",
        "            }\n",
        "\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                info = ydl.extract_info(video_url, download=True)\n",
        "                video_path = ydl.prepare_filename(info)\n",
        "\n",
        "            if os.path.exists(video_path):\n",
        "                frames = self.extract_frames(video_path)\n",
        "\n",
        "                for frame_idx, frame in enumerate(frames):\n",
        "                    ad_region = self.detect_ad_strip(frame)\n",
        "\n",
        "                    if ad_region:\n",
        "                        frame_path = os.path.join(\n",
        "                            self.output_dir, \"frames\",\n",
        "                            f\"{video_id}_frame_{frame_idx}.jpg\")\n",
        "                        cv2.imwrite(frame_path, frame)\n",
        "\n",
        "                        ad_text, confidence = await self.extract_text_with_claude(frame, ad_region)\n",
        "\n",
        "                        if ad_text:\n",
        "                            ad_details = AdDetails(\n",
        "                                video_id=video_id,\n",
        "                                video_title=video_title,\n",
        "                                timestamp=float(frame_idx) / 30.0,\n",
        "                                ad_text=ad_text,\n",
        "                                confidence_score=float(confidence),\n",
        "                                ad_position=tuple(int(x) for x in ad_region),\n",
        "                                processed_date=datetime.now().isoformat()\n",
        "                            )\n",
        "                            self.results.append(ad_details)\n",
        "                            print(f\"Found ad in video {video_id} at frame {frame_idx}\")\n",
        "                            print(f\"Ad text: {ad_text}\")\n",
        "\n",
        "                os.remove(video_path)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing video {video_id}: {str(e)}\")\n",
        "\n",
        "    async def process_playlist(self):\n",
        "        try:\n",
        "            print(f\"Processing playlist: {self.playlist_url}\")\n",
        "            videos = self.get_playlist_videos()\n",
        "\n",
        "            if not videos:\n",
        "                print(\"No videos found in playlist\")\n",
        "                return\n",
        "\n",
        "            print(f\"Found {len(videos)} videos\")\n",
        "\n",
        "            semaphore = asyncio.Semaphore(2)\n",
        "\n",
        "            async def process_with_semaphore(video_id, video_title):\n",
        "                async with semaphore:\n",
        "                    await self.process_video(video_id, video_title)\n",
        "                    await asyncio.sleep(1)\n",
        "\n",
        "            tasks = [process_with_semaphore(vid_id, title) for vid_id, title in videos]\n",
        "            await asyncio.gather(*tasks)\n",
        "\n",
        "            self.save_results()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing playlist: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def save_results(self):\n",
        "        results_file = os.path.join(self.output_dir, \"scan_results.json\")\n",
        "        results_data = [result.to_dict() for result in self.results]\n",
        "\n",
        "        with open(results_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(results_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(f\"Results saved to {results_file}\")\n",
        "        print(f\"Found {len(self.results)} ads across all videos\")\n",
        "\n"
      ],
      "metadata": {
        "id": "1QClvyvctbDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "playlist_url = \"https://www.youtube.com/playlist?list=PLTycFjvfXg-sYpyfA4a_lcIbMXhVtQrxO\"\n",
        "scanner = YouTubeAdScanner(playlist_url)\n",
        "await scanner.process_playlist()  # Use await directly in Colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbHw9uKwuWa7",
        "outputId": "71439c1b-9dce-4d60-c1df-2ad5c883a998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing playlist: https://www.youtube.com/playlist?list=PLTycFjvfXg-sYpyfA4a_lcIbMXhVtQrxO\n",
            "Found 4 videos\n",
            "Processing video: PM Modi Hails Mahayuti Landslide Victory In Maharashtra Elections | Ntv (oP-xZpQkOJ4)\n",
            "Found ad in video oP-xZpQkOJ4 at frame 0\n",
            "Ad text: In this image, there appears to be a \"NO\" logo in white text against a red background, with what looks like \"MAKING\" text underneath it. Below that, there's text that reads \"DON'T MISS\" where \"DON'T\" appears in white text and \"MISS\" appears in yellow text, all on a red banner or background.\n",
            "Found ad in video oP-xZpQkOJ4 at frame 1\n",
            "Ad text: This appears to be some kind of header or banner with a red background. It contains \"NO\" with some additional text next to it, and \"DON'T MISS\" in white and yellow text. The design appears to be part of a website or digital interface, with a clean, bold style typical of web banners or notification bars.\n",
            "Found ad in video oP-xZpQkOJ4 at frame 2\n",
            "Ad text: In this image, there appears to be a red banner or header with \"DON'T MISS\" text prominently displayed. The \"MISS\" portion appears to be in yellow text, while \"DON'T\" is in white. On the left side of the banner, there appears to be a \"NO\" logo or branding element, though the complete text or branding isn't fully clear from this cropped view.\n",
            "Found ad in video oP-xZpQkOJ4 at frame 3\n",
            "Ad text: In this image, there appears to be a red banner or header with \"DON'T MISS\" text displayed prominently. The word \"MISS\" appears to be in yellow text while \"DON'T\" is in white. On the left side of the banner, there appears to be a \"NO\" logo in what seems to be part of a larger brand identity, though the full text isn't clearly visible in this cropped view.\n",
            "Found ad in video oP-xZpQkOJ4 at frame 4\n",
            "Ad text: In this image, there's a header or banner section that contains \"NO\" text followed by \"DON'T MISS\" text, where \"MISS\" appears to be in yellow lettering. The \"NO\" appears to be part of a logo or branding element with additional text that's partially visible but not fully clear in this cropped view.\n",
            "Processing video: కార్తిక శనివారం శుభవేళ లింగ రూపంలో సాక్షాత్కారం అయినా శివుడిని దర్శించడం మహాద్భుతం | Lingodbhavam (4FR4MHGMj0o)\n",
            "Found ad in video 4FR4MHGMj0o at frame 0\n",
            "Ad text: In this very dark image, I can see the blue and white NASA \"worm\" logo - which is NASA's classic text-based logo spelled out in a distinctive stylized font. Without brightening the image, it's difficult to make out any other text or logos clearly due to the extremely dark/black background.\n",
            "Found ad in video 4FR4MHGMj0o at frame 1\n",
            "Ad text: This appears to be a screenshot or banner image that contains the text/logo \"BANDAI NAMCO Entertainment Inc.\" in white letters on a black background.\n",
            "Found ad in video 4FR4MHGMj0o at frame 2\n",
            "Ad text: In this dark image, there appears to be text and logos displayed via LED or illuminated signs. The most prominent appears to be a Rockstar energy drink logo/sign. The image appears to be taken at night or in a dark setting, which makes the illuminated signs stand out against the black background.\n",
            "Found ad in video 4FR4MHGMj0o at frame 3\n",
            "Ad text: The image shows \"r/Overwatch\" which appears to be the subreddit name, along with what looks like a dark or black header/banner image. Due to the dark nature of the image, it's difficult to make out any other distinct logos or text clearly.\n",
            "Found ad in video 4FR4MHGMj0o at frame 4\n",
            "Ad text: The image appears to be very dark or low contrast, but I can make out text that reads \"NFNF 2024\" which appears to be displayed in a video game or stylized digital format. The text appears to be lit up or glowing against a dark background.\n",
            "Processing video: కోటి దీపోత్సవ జ్ఞానదీపాన్ని వెలిగించిన తర్వాత మీ ఇష్టదైవాన్ని స్మరించండి.. సకల శుభాలు చేకూరుతాయి..! (sHVqXoWQrZ4)\n",
            "Found ad in video sHVqXoWQrZ4 at frame 0\n",
            "Ad text: This image appears to be quite dark and stretched horizontally, making it difficult to make out many details. I don't see any clearly visible logos or text in this highly compressed or cropped image. The image seems to have some blurry lights or illuminated elements but the text, if any exists, is not legible from what's shown.\n",
            "Found ad in video sHVqXoWQrZ4 at frame 1\n",
            "Ad text: This appears to be a very dark or dimly lit image, making it difficult to clearly make out any specific logos or text. The image has a reddish tint or glow, but I cannot definitively identify any readable text or logos from what is visible in this cropped, low-light photo.\n",
            "Found ad in video sHVqXoWQrZ4 at frame 2\n",
            "Ad text: This appears to be a dark image and I can see what looks like a Walmart logo, though the image quality and lighting make it difficult to make out any other clear text or logos with certainty.\n",
            "Found ad in video sHVqXoWQrZ4 at frame 3\n",
            "Ad text: I can see what appears to be \"Yoshi's\" text/logo in this somewhat dark and blurry image. The image appears to be taken in what could be a performance venue or nightclub setting, with some lighting visible, but the text/logo detail is limited due to the image quality and lighting conditions.\n",
            "Found ad in video sHVqXoWQrZ4 at frame 4\n",
            "Ad text: From this dimly lit image, I can make out what appears to be the \"Paramount DVD\" logo, which is typically used on DVD releases from Paramount Pictures. However, due to the dark and somewhat blurry nature of the image, it's difficult to make out any other text or logos clearly.\n",
            "Processing video: తెలంగాణ మంత్రి శ్రీ కోమటిరెడ్డి వెంకట్ రెడ్డి గారి ఆధ్యాత్మిక ప్రసంగం : Sri Komatireddy Venkat Reddy (GYFHrXMgnD8)\n",
            "Found ad in video GYFHrXMgnD8 at frame 0\n",
            "Ad text: This appears to be a blurry or cropped image that shows what looks like text or patterns in yellow tones along a horizontal strip, but it's too unclear or distorted to make out any specific logos or readable text.\n",
            "Found ad in video GYFHrXMgnD8 at frame 1\n",
            "Ad text: This appears to be a very narrow, cropped image, possibly a banner or footer from a webpage or document. The image quality and resolution make it difficult to clearly identify any specific logos or text - it shows what seems to be a decorative border or pattern with some yellow/orange and darker colored elements, but I cannot make out any distinct logos or readable text in this compressed view.\n",
            "Found ad in video GYFHrXMgnD8 at frame 2\n",
            "Ad text: This appears to be a panoramic or cropped header-style image that is quite distorted and blurry. The image quality and compression make it difficult to clearly identify any specific logos or text. The image has a dark background with what looks like some yellow/gold elements and possibly some reddish tones, but any text or logos are not clearly legible in this format.\n",
            "Found ad in video GYFHrXMgnD8 at frame 3\n",
            "Ad text: This appears to be a decorative banner or header image with what looks like autumn or fall-themed elements like leaves and what might be pumpkins or gourds, but I don't see any clear logos or text in this particular image. The image appears to be quite compressed/narrow and has a somewhat vintage or textured appearance.\n",
            "Found ad in video GYFHrXMgnD8 at frame 4\n",
            "Ad text: This appears to be a thin decorative banner or border image with what looks like autumn or fall-themed elements like pumpkins and fall flowers/foliage. I don't see any clear logos or readable text in this image - it appears to be purely decorative in nature with a rustic or harvest theme.\n",
            "Results saved to ad_scan_results/scan_results.json\n",
            "Found 20 ads across all videos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import List, Optional, Dict, Any\n",
        "import json\n",
        "from datetime import datetime\n",
        "import asyncio\n",
        "import yt_dlp\n",
        "import anthropic\n",
        "import base64\n",
        "import io\n",
        "\n",
        "# Replace this with your API key\n",
        "CLAUDE_API_KEY = \"your_api_key_here\"\n",
        "\n",
        "@dataclass\n",
        "class AdDetails:\n",
        "    video_id: str\n",
        "    video_title: str\n",
        "    timestamp: float\n",
        "    company_name: str\n",
        "    offers: List[str]\n",
        "    disclaimer_text: str\n",
        "    ad_position: tuple\n",
        "    processed_date: str\n",
        "\n",
        "    def to_dict(self) -> Dict[str, Any]:\n",
        "        result = asdict(self)\n",
        "        result['ad_position'] = list(result['ad_position'])\n",
        "        return result\n",
        "\n",
        "class YouTubeAdScanner:\n",
        "    def __init__(self, playlist_url: str, output_dir: str = \"ad_scan_results\"):\n",
        "        self.playlist_url = playlist_url\n",
        "        self.output_dir = output_dir\n",
        "        self.results: List[AdDetails] = []\n",
        "        self.client = anthropic.Anthropic(api_key=CLAUDE_API_KEY)\n",
        "\n",
        "        # Create output directories\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        os.makedirs(os.path.join(output_dir, \"frames\"), exist_ok=True)\n",
        "        os.makedirs(os.path.join(output_dir, \"temp\"), exist_ok=True)\n",
        "\n",
        "        # Configure yt-dlp options\n",
        "        self.ydl_opts = {\n",
        "            'format': 'best[height<=720]',\n",
        "            'quiet': True,\n",
        "            'no_warnings': True,\n",
        "            'extract_flat': True,\n",
        "        }\n",
        "\n",
        "    def get_playlist_videos(self):\n",
        "        with yt_dlp.YoutubeDL(self.ydl_opts) as ydl:\n",
        "            try:\n",
        "                playlist_info = ydl.extract_info(self.playlist_url, download=False)\n",
        "                if 'entries' in playlist_info:\n",
        "                    return [(entry['id'], entry['title']) for entry in playlist_info['entries']]\n",
        "                return []\n",
        "            except Exception as e:\n",
        "                print(f\"Error extracting playlist info: {str(e)}\")\n",
        "                return []\n",
        "\n",
        "    def extract_frames(self, video_path: str, num_frames: int = 5) -> List[np.ndarray]:\n",
        "        frames = []\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "        for _ in range(num_frames):\n",
        "            ret, frame = cap.read()\n",
        "            if ret:\n",
        "                frames.append(frame)\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        cap.release()\n",
        "        return frames\n",
        "\n",
        "    def detect_ad_strip(self, frame: np.ndarray) -> Optional[tuple]:\n",
        "        \"\"\"Extract the bottom advertisement strip from the frame.\"\"\"\n",
        "        height, width = frame.shape[:2]\n",
        "\n",
        "        # Define the bottom region (approximately last 10% of the frame)\n",
        "        bottom_start = int(height * 0.9)\n",
        "\n",
        "        # Return coordinates for bottom strip\n",
        "        return (0, bottom_start, width, height - bottom_start)\n",
        "\n",
        "    def image_to_base64(self, image: np.ndarray) -> str:\n",
        "        \"\"\"Convert an OpenCV image to base64 string.\"\"\"\n",
        "        # Convert from BGR to RGB\n",
        "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Convert to PIL Image\n",
        "        pil_image = Image.fromarray(image_rgb)\n",
        "\n",
        "        # Save to bytes buffer\n",
        "        buffer = io.BytesIO()\n",
        "        pil_image.save(buffer, format='JPEG')\n",
        "\n",
        "        # Get base64 string\n",
        "        base64_string = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
        "        return base64_string\n",
        "\n",
        "    async def extract_text_with_claude(self, frame: np.ndarray, ad_region: tuple) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze advertisement using Claude's vision capabilities.\"\"\"\n",
        "        try:\n",
        "            x, y, w, h = ad_region\n",
        "            ad_image = frame[y:y+h, x:x+w]\n",
        "\n",
        "            # Convert image to base64\n",
        "            image_base64 = self.image_to_base64(ad_image)\n",
        "\n",
        "            # Create message with Claude\n",
        "            message = self.client.messages.create(\n",
        "                model=\"claude-3-5-sonnet-20241022\",\n",
        "                max_tokens=1024,\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": [\n",
        "                            {\n",
        "                                \"type\": \"image\",\n",
        "                                \"source\": {\n",
        "                                    \"type\": \"base64\",\n",
        "                                    \"media_type\": \"image/jpeg\",\n",
        "                                    \"data\": image_base64,\n",
        "                                },\n",
        "                            },\n",
        "                            {\n",
        "                                \"type\": \"text\",\n",
        "                                \"text\": \"Look at the bottom banner/advertisement strip of this image. Tell me all the promotional offers, deals, or advertisement text you can see. Format your response as a JSON with these fields: company_name, offers (array of strings), and any_disclaimer_text. Only analyze the bottom advertisement strip.\"\n",
        "                            }\n",
        "                        ],\n",
        "                    }\n",
        "                ],\n",
        "            )\n",
        "\n",
        "            # Extract JSON from Claude's response\n",
        "            response_text = message.content[0].text.strip()\n",
        "\n",
        "            try:\n",
        "                # Try to parse JSON from the response\n",
        "                ad_info = json.loads(response_text)\n",
        "            except json.JSONDecodeError:\n",
        "                # If JSON parsing fails, create a basic structure\n",
        "                print(f\"Failed to parse JSON from Claude's response. Raw response: {response_text}\")\n",
        "                ad_info = {\n",
        "                    \"company_name\": \"\",\n",
        "                    \"offers\": [],\n",
        "                    \"any_disclaimer_text\": \"\"\n",
        "                }\n",
        "\n",
        "            return ad_info\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error using Claude for text extraction: {str(e)}\")\n",
        "            return {\n",
        "                \"company_name\": \"\",\n",
        "                \"offers\": [],\n",
        "                \"any_disclaimer_text\": \"\"\n",
        "            }\n",
        "\n",
        "    async def process_video(self, video_id: str, video_title: str):\n",
        "        try:\n",
        "            print(f\"Processing video: {video_title} ({video_id})\")\n",
        "\n",
        "            video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "            ydl_opts = {\n",
        "                'format': 'best[height<=720]',\n",
        "                'quiet': True,\n",
        "                'no_warnings': True,\n",
        "                'outtmpl': os.path.join(self.output_dir, \"temp\", f\"{video_id}.%(ext)s\")\n",
        "            }\n",
        "\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                info = ydl.extract_info(video_url, download=True)\n",
        "                video_path = ydl.prepare_filename(info)\n",
        "\n",
        "            if os.path.exists(video_path):\n",
        "                frames = self.extract_frames(video_path)\n",
        "\n",
        "                for frame_idx, frame in enumerate(frames):\n",
        "                    ad_region = self.detect_ad_strip(frame)\n",
        "\n",
        "                    if ad_region:\n",
        "                        frame_path = os.path.join(\n",
        "                            self.output_dir, \"frames\",\n",
        "                            f\"{video_id}_frame_{frame_idx}.jpg\")\n",
        "                        cv2.imwrite(frame_path, frame)\n",
        "\n",
        "                        ad_info = await self.extract_text_with_claude(frame, ad_region)\n",
        "\n",
        "                        if ad_info and (ad_info.get(\"company_name\") or ad_info.get(\"offers\")):\n",
        "                            ad_details = AdDetails(\n",
        "                                video_id=video_id,\n",
        "                                video_title=video_title,\n",
        "                                timestamp=float(frame_idx) / 30.0,\n",
        "                                company_name=ad_info.get(\"company_name\", \"\"),\n",
        "                                offers=ad_info.get(\"offers\", []),\n",
        "                                disclaimer_text=ad_info.get(\"any_disclaimer_text\", \"\"),\n",
        "                                ad_position=tuple(int(x) for x in ad_region),\n",
        "                                processed_date=datetime.now().isoformat()\n",
        "                            )\n",
        "                            self.results.append(ad_details)\n",
        "                            print(f\"Found ad in video {video_id} at frame {frame_idx}\")\n",
        "                            print(f\"Company: {ad_info.get('company_name', '')}\")\n",
        "                            print(f\"Offers: {ad_info.get('offers', [])}\")\n",
        "\n",
        "                os.remove(video_path)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing video {video_id}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    async def process_playlist(self):\n",
        "        try:\n",
        "            print(f\"Processing playlist: {self.playlist_url}\")\n",
        "            videos = self.get_playlist_videos()\n",
        "\n",
        "            if not videos:\n",
        "                print(\"No videos found in playlist\")\n",
        "                return\n",
        "\n",
        "            print(f\"Found {len(videos)} videos\")\n",
        "\n",
        "            semaphore = asyncio.Semaphore(2)\n",
        "\n",
        "            async def process_with_semaphore(video_id, video_title):\n",
        "                async with semaphore:\n",
        "                    await self.process_video(video_id, video_title)\n",
        "                    await asyncio.sleep(1)\n",
        "\n",
        "            tasks = [process_with_semaphore(vid_id, title) for vid_id, title in videos]\n",
        "            await asyncio.gather(*tasks)\n",
        "\n",
        "            self.save_results()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing playlist: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def save_results(self):\n",
        "        results_file = os.path.join(self.output_dir, \"scan_results.json\")\n",
        "        results_data = [result.to_dict() for result in self.results]\n",
        "\n",
        "        with open(results_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(results_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(f\"Results saved to {results_file}\")\n",
        "        print(f\"Found {len(self.results)} ads across all videos\")\n",
        "\n"
      ],
      "metadata": {
        "id": "t6G_bg9JwcDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "playlist_url = \"https://www.youtube.com/playlist?list=PLTycFjvfXg-sYpyfA4a_lcIbMXhVtQrxO\"\n",
        "scanner = YouTubeAdScanner(playlist_url)\n",
        "await scanner.process_playlist()  # Use await directly in Colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Co0AHHQdwoOo",
        "outputId": "356825e0-3837-4a2a-ee94-e060601f0317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing playlist: https://www.youtube.com/playlist?list=PLTycFjvfXg-sYpyfA4a_lcIbMXhVtQrxO\n",
            "Found 4 videos\n",
            "Processing video: PM Modi Hails Mahayuti Landslide Victory In Maharashtra Elections | Ntv (oP-xZpQkOJ4)\n",
            "Failed to parse JSON from Claude's response. Raw response: {\n",
            "  \"company_name\": \"Komanecvim\",\n",
            "  \"offers\": [\n",
            "    \"GET FREE 10 YEARS\",\n",
            "    \"0-040-20000000\" // appears to be some form of contact number/code\n",
            "  ],\n",
            "  \"any_disclaimer_text\": \"No visible disclaimers in the banner strip\"\n",
            "}\n",
            "\n",
            "Note: There appears to be potentially another text/number sequence starting with \"0-040-\" on the left side of the banner, but it's partially cut off and not fully legible in the image.\n",
            "Found ad in video oP-xZpQkOJ4 at frame 1\n",
            "Company: Kamani Evm Factory Outlet\n",
            "Offers: ['GET FREE 10 YEARS', 'Less Expense More Saving']\n",
            "Found ad in video oP-xZpQkOJ4 at frame 2\n",
            "Company: Koman Evolution Factory Outlet\n",
            "Offers: ['Get Free 10 Years Service', 'Less Expense More Saving']\n",
            "Failed to parse JSON from Claude's response. Raw response: {\n",
            "  \"company_name\": \"Komani Evin Factory Outlet\",\n",
            "  \"offers\": [\n",
            "    \"Less Expense More Saving\",\n",
            "    \"Get Free 10 Years\",\n",
            "    \"Call: 0404-20000000\"\n",
            "  ],\n",
            "  \"any_disclaimer_text\": \"\"\n",
            "}\n",
            "\n",
            "Note: The text appears to be in a dark blue banner strip with white text. Some portions of the text are partially visible due to image quality, but I've included what can be clearly read. The phone number format may vary from what's shown as parts are not fully legible.\n",
            "Failed to parse JSON from Claude's response. Raw response: {\n",
            "  \"company_name\": \"Factory Outlet\",\n",
            "  \"offers\": [\n",
            "    \"Less Expense More Saving\",\n",
            "    \"Get Free 10 Years Service\",\n",
            "    \"O-040-120000000\" // appears twice on the banner\n",
            "  ],\n",
            "  \"any_disclaimer_text\": \"none visible in the bottom strip\",\n",
            "  \"additional_details\": {\n",
            "    \"banner_color\": \"dark blue with gold/yellow text\",\n",
            "    \"visible_logos\": [\"Kaman EVA\"]\n",
            "  }\n",
            "}\n",
            "Processing video: కార్తిక శనివారం శుభవేళ లింగ రూపంలో సాక్షాత్కారం అయినా శివుడిని దర్శించడం మహాద్భుతం | Lingodbhavam (4FR4MHGMj0o)\n",
            "Found ad in video 4FR4MHGMj0o at frame 0\n",
            "Company: South India Jewels\n",
            "Offers: []\n",
            "Found ad in video 4FR4MHGMj0o at frame 1\n",
            "Company: South India Shopping Mall\n",
            "Offers: ['Advertisement appears to be a banner/strip for clothing retail', 'Shows glimpses of traditional and casual wear displays']\n",
            "Failed to parse JSON from Claude's response. Raw response: {\n",
            "  \"company_name\": \"South India Shopping Mall\",\n",
            "  \"offers\": [\"Anniversary Sale\"],\n",
            "  \"any_disclaimer_text\": null,\n",
            "  \"notes\": \"This appears to be a promotional banner strip showing repeated store branding and sale announcement, with alternating images. The text and branding elements are partially visible due to the compressed nature of the banner.\"\n",
            "}\n",
            "\n",
            "The banner appears to be a repeating promotional strip, but due to the compressed and stretched nature of the image, I can only definitively make out the \"South India\" branding elements and what appears to be an anniversary sale promotion. If there are other specific deals or text present, they're not clearly legible in this format.\n",
            "Found ad in video 4FR4MHGMj0o at frame 3\n",
            "Company: South India Shopping Mall\n",
            "Offers: []\n",
            "Found ad in video 4FR4MHGMj0o at frame 4\n",
            "Company: South India Shopping Mall\n",
            "Offers: []\n",
            "Processing video: కోటి దీపోత్సవ జ్ఞానదీపాన్ని వెలిగించిన తర్వాత మీ ఇష్టదైవాన్ని స్మరించండి.. సకల శుభాలు చేకూరుతాయి..! (sHVqXoWQrZ4)\n",
            "Found ad in video sHVqXoWQrZ4 at frame 0\n",
            "Company: South India Shopping Mall\n",
            "Offers: []\n",
            "Failed to parse JSON from Claude's response. Raw response: {\n",
            "  \"company_name\": \"South India Shopping Mall\",\n",
            "  \"offers\": [],\n",
            "  \"any_disclaimer_text\": \"\"\n",
            "}\n",
            "\n",
            "Note: The bottom banner appears to be a repetitive strip showing what seems to be a clothing store or shopping mall logo, but the text is not clearly legible enough to identify specific offers or promotional text. It shows alternating branding elements of what appears to be \"South India\" branded signage with some additional imagery, but no distinct promotional offers are visible in the banner strip.\n",
            "Failed to parse JSON from Claude's response. Raw response: {\n",
            "    \"company_name\": \"South India Shopping Mall\",\n",
            "    \"offers\": [],\n",
            "    \"any_disclaimer_text\": \"\"\n",
            "}\n",
            "\n",
            "Note: While I can see the banner appears to be a promotional strip showing what seems to be some sort of shopping mall or retail establishment branding with \"South India\" text, the image quality and resolution of the banner strip is too low to make out any specific promotional offers or disclaimer text. The banner appears to be a repeating pattern showing some store imagery and logos, but the text details are not clearly legible.\n",
            "Found ad in video sHVqXoWQrZ4 at frame 3\n",
            "Company: South India Jewellers\n",
            "Offers: ['The bottom strip appears to be a composite promotional banner showing repeated branding elements']\n",
            "Found ad in video sHVqXoWQrZ4 at frame 4\n",
            "Company: Seematti & South India Shopping Mall\n",
            "Offers: []\n",
            "Processing video: తెలంగాణ మంత్రి శ్రీ కోమటిరెడ్డి వెంకట్ రెడ్డి గారి ఆధ్యాత్మిక ప్రసంగం : Sri Komatireddy Venkat Reddy (GYFHrXMgnD8)\n",
            "Found ad in video GYFHrXMgnD8 at frame 0\n",
            "Company: BIG C\n",
            "Offers: ['10% CASH BACK', '0 DOWN PAYMENT', 'ASSURED GIFT ON MOBILE PURCHASE']\n",
            "Found ad in video GYFHrXMgnD8 at frame 1\n",
            "Company: BIG C\n",
            "Offers: ['10% CASH BACK', '0 DOWN PAYMENT', 'ASSURED GIFT ON MOBILE PURCHASE']\n",
            "Found ad in video GYFHrXMgnD8 at frame 2\n",
            "Company: BIG C\n",
            "Offers: ['10% CASH BACK', '0 DOWN PAYMENT', 'ASSURED GIFT ON MOBILE PURCHASE']\n",
            "Found ad in video GYFHrXMgnD8 at frame 3\n",
            "Company: BIG C\n",
            "Offers: ['10% CASH BACK', '0 DOWN PAYMENT', 'ASSURED GIFT ON MOBILE PURCHASE']\n",
            "Found ad in video GYFHrXMgnD8 at frame 4\n",
            "Company: BIG C\n",
            "Offers: ['10% CASH BACK', '0 DOWN PAYMENT', 'ASSURED GIFT ON MOBILE PURCHASE']\n",
            "Results saved to ad_scan_results/scan_results.json\n",
            "Found 14 ads across all videos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas matplotlib seaborn plotly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9biNLcCy61X",
        "outputId": "898202fc-83c5-49c4-e8bc-6d602ddd1c86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.24.1)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (9.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "from collections import Counter\n",
        "import os\n",
        "from typing import List, Dict, Any\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "class AdReportGenerator:\n",
        "    def __init__(self, json_path: str, output_dir: str = \"ad_reports\"):\n",
        "        self.json_path = json_path\n",
        "        self.output_dir = output_dir\n",
        "        self.data = None\n",
        "        self.df = None\n",
        "\n",
        "        # Create output directory\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"Load and parse the JSON data.\"\"\"\n",
        "        with open(self.json_path, 'r', encoding='utf-8') as f:\n",
        "            self.data = json.load(f)\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        self.df = pd.DataFrame(self.data)\n",
        "\n",
        "        # Convert processed_date to datetime\n",
        "        self.df['processed_date'] = pd.to_datetime(self.df['processed_date'])\n",
        "\n",
        "        # Explode the offers array into separate rows\n",
        "        self.df_offers = self.df.explode('offers').reset_index(drop=True)\n",
        "\n",
        "        # Remove any None or empty values from offers\n",
        "        self.df_offers = self.df_offers[self.df_offers['offers'].notna()]\n",
        "        self.df_offers = self.df_offers[self.df_offers['offers'] != '']\n",
        "\n",
        "    def generate_summary_stats(self) -> Dict[str, Any]:\n",
        "        \"\"\"Generate summary statistics.\"\"\"\n",
        "        summary = {\n",
        "            'total_ads_detected': len(self.df),\n",
        "            'unique_companies': len(self.df['company_name'].unique()),\n",
        "            'total_videos_analyzed': len(self.df['video_id'].unique()),\n",
        "            'unique_offers': len(self.df_offers['offers'].unique()) if not self.df_offers.empty else 0,\n",
        "            'most_common_company': self.df['company_name'].mode().iloc[0] if not self.df['company_name'].empty else 'N/A',\n",
        "            'avg_offers_per_ad': len(self.df_offers) / len(self.df) if len(self.df) > 0 else 0,\n",
        "            'date_range': {\n",
        "                'start': self.df['processed_date'].min().strftime('%Y-%m-%d') if not self.df.empty else 'N/A',\n",
        "                'end': self.df['processed_date'].max().strftime('%Y-%m-%d') if not self.df.empty else 'N/A'\n",
        "            }\n",
        "        }\n",
        "        return summary\n",
        "\n",
        "    def analyze_offers(self) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze offers and their patterns.\"\"\"\n",
        "        if self.df_offers.empty:\n",
        "            return {\n",
        "                'most_common_offers': {},\n",
        "                'offers_by_company': {},\n",
        "                'avg_offers_per_company': 0\n",
        "            }\n",
        "\n",
        "        offer_analysis = {\n",
        "            'most_common_offers': self.df_offers['offers'].value_counts().head(10).to_dict(),\n",
        "            'offers_by_company': self.df.groupby('company_name')['offers'].apply(lambda x: [item for sublist in x for item in sublist]).to_dict(),\n",
        "            'avg_offers_per_company': self.df.groupby('company_name').agg({'offers': lambda x: sum(len(i) for i in x)}).mean()['offers']\n",
        "        }\n",
        "        return offer_analysis\n",
        "\n",
        "    def generate_visualizations(self):\n",
        "        \"\"\"Generate various visualizations for the report.\"\"\"\n",
        "\n",
        "        # Only generate visualizations if we have data\n",
        "        if self.df.empty:\n",
        "            print(\"No data available for visualizations\")\n",
        "            return\n",
        "\n",
        "        # 1. Companies and their ad frequencies\n",
        "        company_counts = self.df['company_name'].value_counts().reset_index()\n",
        "        company_counts.columns = ['company', 'count']\n",
        "        fig1 = px.bar(company_counts,\n",
        "                     x='company',\n",
        "                     y='count',\n",
        "                     title='Ad Frequency by Company',\n",
        "                     labels={'company': 'Company', 'count': 'Number of Ads'},\n",
        "                     color='company')\n",
        "        fig1.write_html(os.path.join(self.output_dir, 'company_frequency.html'))\n",
        "\n",
        "        # 2. Offer types distribution (only if we have offers data)\n",
        "        if not self.df_offers.empty:\n",
        "            fig2 = px.pie(self.df_offers,\n",
        "                         names='offers',\n",
        "                         title='Distribution of Offer Types')\n",
        "            fig2.write_html(os.path.join(self.output_dir, 'offer_distribution.html'))\n",
        "\n",
        "        # 3. Timeline of ads\n",
        "        self.df['end_date'] = self.df['processed_date'] + pd.Timedelta(minutes=15)\n",
        "        fig3 = px.timeline(self.df,\n",
        "                          x_start='processed_date',\n",
        "                          x_end='end_date',\n",
        "                          y='company_name',\n",
        "                          color='company_name',\n",
        "                          title='Timeline of Ad Appearances')\n",
        "        fig3.write_html(os.path.join(self.output_dir, 'ad_timeline.html'))\n",
        "\n",
        "        # 4. Heatmap of ads by day and hour\n",
        "        self.df['hour'] = self.df['processed_date'].dt.hour\n",
        "        self.df['day'] = self.df['processed_date'].dt.day_name()\n",
        "\n",
        "        # Create the crosstab and fill NaN with 0\n",
        "        heatmap_data = pd.crosstab(\n",
        "            self.df['day'],\n",
        "            self.df['hour']\n",
        "        ).fillna(0)\n",
        "\n",
        "        fig4 = px.imshow(heatmap_data,\n",
        "                        title='Ad Frequency Heatmap by Day and Hour',\n",
        "                        labels=dict(x='Hour of Day', y='Day of Week', color='Number of Ads'))\n",
        "        fig4.write_html(os.path.join(self.output_dir, 'ad_heatmap.html'))\n",
        "\n",
        "    def generate_html_report(self):\n",
        "        \"\"\"Generate a comprehensive HTML report.\"\"\"\n",
        "        summary_stats = self.generate_summary_stats()\n",
        "        offer_analysis = self.analyze_offers()\n",
        "\n",
        "        html_content = f\"\"\"\n",
        "        <!DOCTYPE html>\n",
        "        <html>\n",
        "        <head>\n",
        "            <title>Ad Campaign Analysis Report</title>\n",
        "            <style>\n",
        "                body {{ font-family: Arial, sans-serif; margin: 40px; }}\n",
        "                .container {{ max-width: 1200px; margin: 0 auto; }}\n",
        "                .section {{ margin-bottom: 40px; }}\n",
        "                .stat-box {{\n",
        "                    background: #f5f5f5;\n",
        "                    padding: 20px;\n",
        "                    border-radius: 5px;\n",
        "                    margin-bottom: 20px;\n",
        "                }}\n",
        "                .flex-container {{\n",
        "                    display: flex;\n",
        "                    flex-wrap: wrap;\n",
        "                    gap: 20px;\n",
        "                }}\n",
        "                .stat-item {{\n",
        "                    flex: 1;\n",
        "                    min-width: 200px;\n",
        "                    background: white;\n",
        "                    padding: 15px;\n",
        "                    border-radius: 5px;\n",
        "                    box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
        "                }}\n",
        "                table {{\n",
        "                    width: 100%;\n",
        "                    border-collapse: collapse;\n",
        "                    margin-top: 20px;\n",
        "                }}\n",
        "                th, td {{\n",
        "                    padding: 12px;\n",
        "                    border: 1px solid #ddd;\n",
        "                    text-align: left;\n",
        "                }}\n",
        "                th {{ background: #f5f5f5; }}\n",
        "                h1, h2 {{ color: #333; }}\n",
        "                .chart-container {{ margin: 20px 0; height: 600px; }}\n",
        "                iframe {{ border: none; width: 100%; height: 100%; }}\n",
        "            </style>\n",
        "        </head>\n",
        "        <body>\n",
        "            <div class=\"container\">\n",
        "                <h1>Ad Campaign Analysis Report</h1>\n",
        "                <p>Report generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
        "\n",
        "                <div class=\"section\">\n",
        "                    <h2>Summary Statistics</h2>\n",
        "                    <div class=\"flex-container\">\n",
        "                        <div class=\"stat-item\">\n",
        "                            <h3>Total Ads Detected</h3>\n",
        "                            <p>{summary_stats['total_ads_detected']}</p>\n",
        "                        </div>\n",
        "                        <div class=\"stat-item\">\n",
        "                            <h3>Unique Companies</h3>\n",
        "                            <p>{summary_stats['unique_companies']}</p>\n",
        "                        </div>\n",
        "                        <div class=\"stat-item\">\n",
        "                            <h3>Videos Analyzed</h3>\n",
        "                            <p>{summary_stats['total_videos_analyzed']}</p>\n",
        "                        </div>\n",
        "                        <div class=\"stat-item\">\n",
        "                            <h3>Unique Offers</h3>\n",
        "                            <p>{summary_stats['unique_offers']}</p>\n",
        "                        </div>\n",
        "                    </div>\n",
        "                </div>\n",
        "        \"\"\"\n",
        "\n",
        "        # Only add offers section if we have offer data\n",
        "        if offer_analysis['most_common_offers']:\n",
        "            html_content += f\"\"\"\n",
        "                <div class=\"section\">\n",
        "                    <h2>Most Common Offers</h2>\n",
        "                    <table>\n",
        "                        <tr>\n",
        "                            <th>Offer</th>\n",
        "                            <th>Frequency</th>\n",
        "                        </tr>\n",
        "                        {''.join(f\"<tr><td>{offer}</td><td>{count}</td></tr>\"\n",
        "                               for offer, count in offer_analysis['most_common_offers'].items())}\n",
        "                    </table>\n",
        "                </div>\n",
        "            \"\"\"\n",
        "\n",
        "        # Only add company analysis if we have company data\n",
        "        if offer_analysis['offers_by_company']:\n",
        "            html_content += f\"\"\"\n",
        "                <div class=\"section\">\n",
        "                    <h2>Company Analysis</h2>\n",
        "                    <table>\n",
        "                        <tr>\n",
        "                            <th>Company</th>\n",
        "                            <th>Unique Offers</th>\n",
        "                        </tr>\n",
        "                        {''.join(f\"<tr><td>{company}</td><td>{len(set(offers))}</td></tr>\"\n",
        "                               for company, offers in offer_analysis['offers_by_company'].items())}\n",
        "                    </table>\n",
        "                </div>\n",
        "            \"\"\"\n",
        "\n",
        "        # Add visualizations\n",
        "        html_content += \"\"\"\n",
        "                <div class=\"section\">\n",
        "                    <h2>Visualizations</h2>\n",
        "                    <div class=\"chart-container\">\n",
        "                        <iframe src=\"company_frequency.html\"></iframe>\n",
        "                    </div>\n",
        "        \"\"\"\n",
        "\n",
        "        # Only add offer distribution if we have offer data\n",
        "        if not self.df_offers.empty:\n",
        "            html_content += \"\"\"\n",
        "                    <div class=\"chart-container\">\n",
        "                        <iframe src=\"offer_distribution.html\"></iframe>\n",
        "                    </div>\n",
        "            \"\"\"\n",
        "\n",
        "        html_content += \"\"\"\n",
        "                    <div class=\"chart-container\">\n",
        "                        <iframe src=\"ad_timeline.html\"></iframe>\n",
        "                    </div>\n",
        "                    <div class=\"chart-container\">\n",
        "                        <iframe src=\"ad_heatmap.html\"></iframe>\n",
        "                    </div>\n",
        "                </div>\n",
        "            </div>\n",
        "        </body>\n",
        "        </html>\n",
        "        \"\"\"\n",
        "\n",
        "        with open(os.path.join(self.output_dir, 'ad_analysis_report.html'), 'w', encoding='utf-8') as f:\n",
        "            f.write(html_content)\n",
        "\n",
        "    def generate_report(self):\n",
        "        \"\"\"Generate the complete report.\"\"\"\n",
        "        print(\"Loading data...\")\n",
        "        self.load_data()\n",
        "\n",
        "        print(\"Generating visualizations...\")\n",
        "        self.generate_visualizations()\n",
        "\n",
        "        print(\"Generating HTML report...\")\n",
        "        self.generate_html_report()\n",
        "\n",
        "        print(f\"Report generated successfully in {self.output_dir}\")\n",
        "\n",
        "# Usage example\n",
        "if __name__ == \"__main__\":\n",
        "    # Specify the path to your JSON file\n",
        "    json_path = \"/content/ad_scan_results/scan_results_withClaude3.json\"\n",
        "\n",
        "    # Create report generator\n",
        "    report_generator = AdReportGenerator(json_path)\n",
        "\n",
        "    # Generate report\n",
        "    report_generator.generate_report()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkdVdV1NytFy",
        "outputId": "749719b3-d6a9-4e91-94aa-8d44989615ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Generating visualizations...\n",
            "Generating HTML report...\n",
            "Report generated successfully in ad_reports\n"
          ]
        }
      ]
    }
  ]
}